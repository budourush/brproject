{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力→中間(3→2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38631583, -0.965096  ,  1.37103525],\n",
       "       [-0.1344963 ,  0.55414032,  1.45995792]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2行3列\n",
    "W1 = np.random.randn(2,3)\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.random.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.28900825, -1.6988755 ],\n",
       "       [-0.27805485,  0.14264072],\n",
       "       [-0.65263259, -0.7995082 ],\n",
       "       [ 0.01401959,  1.66028256],\n",
       "       [ 0.62091523, -0.06111177],\n",
       "       [ 0.8563265 ,  1.2659296 ],\n",
       "       [ 0.73757722, -0.1452711 ],\n",
       "       [-1.195721  ,  0.43239858],\n",
       "       [ 1.28395218,  0.44982029],\n",
       "       [-0.30737338,  2.45967645]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サンプル数：10、入力変数：2\n",
    "x = np.random.randn(10,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08486782, -2.41716025, -1.48035361],\n",
       "       [ 0.27283635,  0.11566446, -0.94031618],\n",
       "       [ 0.5442572 , -0.04491477, -2.82937323],\n",
       "       [-0.04411384,  0.67477112,  1.67582139],\n",
       "       [-0.04704607, -0.86483544, -0.00526657],\n",
       "       [-0.31647133, -0.35666279,  2.25491514],\n",
       "       [-0.08079533, -1.02406154,  0.03181205],\n",
       "       [ 0.58837395,  1.16186689, -1.77543453],\n",
       "       [-0.37190622, -1.22160169,  1.64971977],\n",
       "       [-0.02747017,  1.42792257,  2.40226175]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1 = np.dot(x, W1) + b1\n",
    "u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47879577, 0.08187347, 0.18537401],\n",
       "       [0.56778909, 0.52888392, 0.28083648],\n",
       "       [0.63280219, 0.48877319, 0.05575739],\n",
       "       [0.48897333, 0.66257067, 0.84235042],\n",
       "       [0.48824065, 0.29633007, 0.49868336],\n",
       "       [0.42153595, 0.41176765, 0.90507366],\n",
       "       [0.47981215, 0.26423702, 0.50795234],\n",
       "       [0.64299197, 0.76167177, 0.14486779],\n",
       "       [0.40808049, 0.22765471, 0.83885317],\n",
       "       [0.49313289, 0.80657742, 0.91699961]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08486782, -2.41716025, -1.48035361],\n",
       "       [ 0.27283635,  0.11566446, -0.94031618],\n",
       "       [ 0.5442572 , -0.04491477, -2.82937323],\n",
       "       [-0.04411384,  0.67477112,  1.67582139],\n",
       "       [-0.04704607, -0.86483544, -0.00526657],\n",
       "       [-0.31647133, -0.35666279,  2.25491514],\n",
       "       [-0.08079533, -1.02406154,  0.03181205],\n",
       "       [ 0.58837395,  1.16186689, -1.77543453],\n",
       "       [-0.37190622, -1.22160169,  1.64971977],\n",
       "       [-0.02747017,  1.42792257,  2.40226175]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = relu(u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.27283635, 0.11566446, 0.        ],\n",
       "       [0.5442572 , 0.        , 0.        ],\n",
       "       [0.        , 0.67477112, 1.67582139],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 2.25491514],\n",
       "       [0.        , 0.        , 0.03181205],\n",
       "       [0.58837395, 1.16186689, 0.        ],\n",
       "       [0.        , 0.        , 1.64971977],\n",
       "       [0.        , 1.42792257, 2.40226175]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中間～出力(3→2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22758727,  0.68929166],\n",
       "       [ 0.34287584, -0.23549611],\n",
       "       [ 1.88101445, -0.7144889 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = np.random.randn(3,2)\n",
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45086271,  0.43201851])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = np.random.randn(2)\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45086271,  0.43201851],\n",
       "       [-0.34911008,  0.5928438 ],\n",
       "       [-0.32699669,  0.80717047],\n",
       "       [ 2.93274425, -0.92424325],\n",
       "       [-0.45086271,  0.43201851],\n",
       "       [ 3.79066526, -1.17909334],\n",
       "       [-0.39102378,  0.40928916],\n",
       "       [ 0.0814198 ,  0.56396464],\n",
       "       [ 2.65228403, -0.74668796],\n",
       "       [ 4.55742651, -1.62064107]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u2 = np.dot(z1,W2) + b2\n",
    "u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim >= 2:\n",
    "        x = x-x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x-np.max(x)\n",
    "        x = np.exp(x)/np.sum(np.exp(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def softmax(x):\n",
    "#     exp_x = np.exp(x - np.max(x))\n",
    "#     return exp_x/np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24339289, 0.75660711])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(u2[2])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29258108, 0.70741892],\n",
       "       [0.28050584, 0.71949416],\n",
       "       [0.24339289, 0.75660711],\n",
       "       [0.97930574, 0.02069426],\n",
       "       [0.29258108, 0.70741892],\n",
       "       [0.99310307, 0.00689693],\n",
       "       [0.30995858, 0.69004142],\n",
       "       [0.38165138, 0.61834862],\n",
       "       [0.96767239, 0.03232761],\n",
       "       [0.99792986, 0.00207014]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(u2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レイヤとしてまとめていく\n",
    "- 変数\n",
    "    - パラメータ(params)\n",
    "    - 勾配(grads)\n",
    "- メソッド\n",
    "    - 順伝播(forward)\n",
    "    - 逆伝播(backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine変換(線形変換)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "# パラメータの初期化\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W,b]\n",
    "# 順伝播\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x,W)+b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu関数(非線形変換)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(2,3)\n",
    "b1 = np.random.randn(3)\n",
    "\n",
    "W2 = np.random.randn(3,2)\n",
    "b2 = np.random.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69917451, -0.36240103,  1.40690571, -0.54367925],\n",
       "       [ 0.23760783,  0.07916339, -0.19210209, -1.24146449],\n",
       "       [ 2.43778237, -1.79271845, -0.70766976,  2.74093594],\n",
       "       [-1.61319896, -0.06019874, -1.67340232, -0.42036341],\n",
       "       [ 1.4762732 ,  0.61875486,  0.02909043,  1.57599212],\n",
       "       [-1.98494917,  0.89421511, -0.14732099, -0.17728354],\n",
       "       [ 1.41973766, -1.63192051, -1.62099343,  0.19265996],\n",
       "       [-0.0993767 , -0.28984028, -0.61443266, -0.49335482],\n",
       "       [-0.34996138, -0.21742351,  1.49785249,  0.39048506],\n",
       "       [ 0.74134643,  0.10235098,  1.22845036,  0.36181149]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(10,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    # パラメータの初期化\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "    # 順伝播\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        return out\n",
    "    \n",
    "    # \n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "        \n",
    "        # Ellipsis = ... (省略記号) = 入力に合わせた次元になる\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 1/(1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0-self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.98201379, 0.04742587])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,4,-3])\n",
    "sigmoid.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19661193, 0.31498076, 0.07065082, 0.2258833 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dout = np.array([1,3,4,5])\n",
    "sigmoid.backward(dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.x = None\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, self.x)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return np.where(self.x>0, dout, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,4,-3])\n",
    "dout = np.array([1,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu.backward(dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax with Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim==1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    # 教師データがOne-Hot表現の場合\n",
    "    if t.size == y.size:\n",
    "        # 一番大きい値のindexを返す\n",
    "        t = t.argmax(axis=1)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # 実測値\n",
    "        self.t = t\n",
    "        # 予測値\n",
    "        self.y = softmax(x)\n",
    "        \n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "    \n",
    "    # ソフトマックスの逆伝播\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        \n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx/batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD(確率的勾配降下法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr*grads[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNの構造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    # 重みの初期化(W,b)\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "    # W,bの初期化\n",
    "        W1 = np.random.randn(n_in, n_hidden)\n",
    "        b1 = np.zeros(n_hidden)\n",
    "        W2 = np.random.randn(n_hidden, n_out)\n",
    "        b2 = np.zeros(n_out)\n",
    "    # レイヤをすべてまとめる\n",
    "        self.layers = [\n",
    "            Affine(W1,b1),\n",
    "#             Relu(),\n",
    "            Sigmoid(),\n",
    "            Affine(W2,b2)\n",
    "        ]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "    # パラメータをまとめる\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    # 推論\n",
    "    def predict(self, x):\n",
    "        for layer  in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    # 順伝播\n",
    "    def forward(self, x, t):\n",
    "        # 予測値の計算\n",
    "        y = self.predict(x)\n",
    "        loss = self.loss_layer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    # 逆伝播\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    # 精度\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t)/float(len(x))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(4, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.71710634,  0.39768265, -1.76501621])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df.iloc[:,-1]\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  0  0\n",
       "1  1  0  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot表現へ変更する\n",
    "t = pd.get_dummies(t)\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas → numpy\n",
    "x = x.values\n",
    "t = t.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習に必要な準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 15\n",
    "n_hidden = 10\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(t)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iters = N//batch_size\n",
    "max_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(n_in=4, n_hidden=n_hidden, n_out=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 iter10/10 loss 0.76\n",
      "epoch 2 iter10/10 loss 0.646\n",
      "epoch 3 iter10/10 loss 0.591\n",
      "epoch 4 iter10/10 loss 0.563\n",
      "epoch 5 iter10/10 loss 0.537\n",
      "epoch 6 iter10/10 loss 0.527\n",
      "epoch 7 iter10/10 loss 0.511\n",
      "epoch 8 iter10/10 loss 0.5\n",
      "epoch 9 iter10/10 loss 0.49\n",
      "epoch 10 iter10/10 loss 0.478\n",
      "epoch 11 iter10/10 loss 0.471\n",
      "epoch 12 iter10/10 loss 0.462\n",
      "epoch 13 iter10/10 loss 0.457\n",
      "epoch 14 iter10/10 loss 0.441\n",
      "epoch 15 iter10/10 loss 0.445\n",
      "epoch 16 iter10/10 loss 0.437\n",
      "epoch 17 iter10/10 loss 0.43\n",
      "epoch 18 iter10/10 loss 0.413\n",
      "epoch 19 iter10/10 loss 0.404\n",
      "epoch 20 iter10/10 loss 0.403\n",
      "epoch 21 iter10/10 loss 0.391\n",
      "epoch 22 iter10/10 loss 0.388\n",
      "epoch 23 iter10/10 loss 0.376\n",
      "epoch 24 iter10/10 loss 0.369\n",
      "epoch 25 iter10/10 loss 0.376\n",
      "epoch 26 iter10/10 loss 0.36\n",
      "epoch 27 iter10/10 loss 0.359\n",
      "epoch 28 iter10/10 loss 0.349\n",
      "epoch 29 iter10/10 loss 0.338\n",
      "epoch 30 iter10/10 loss 0.336\n",
      "epoch 31 iter10/10 loss 0.327\n",
      "epoch 32 iter10/10 loss 0.32\n",
      "epoch 33 iter10/10 loss 0.318\n",
      "epoch 34 iter10/10 loss 0.31\n",
      "epoch 35 iter10/10 loss 0.306\n",
      "epoch 36 iter10/10 loss 0.303\n",
      "epoch 37 iter10/10 loss 0.292\n",
      "epoch 38 iter10/10 loss 0.285\n",
      "epoch 39 iter10/10 loss 0.282\n",
      "epoch 40 iter10/10 loss 0.281\n",
      "epoch 41 iter10/10 loss 0.283\n",
      "epoch 42 iter10/10 loss 0.274\n",
      "epoch 43 iter10/10 loss 0.266\n",
      "epoch 44 iter10/10 loss 0.265\n",
      "epoch 45 iter10/10 loss 0.271\n",
      "epoch 46 iter10/10 loss 0.26\n",
      "epoch 47 iter10/10 loss 0.247\n",
      "epoch 48 iter10/10 loss 0.241\n",
      "epoch 49 iter10/10 loss 0.243\n",
      "epoch 50 iter10/10 loss 0.24\n",
      "epoch 51 iter10/10 loss 0.234\n",
      "epoch 52 iter10/10 loss 0.22\n",
      "epoch 53 iter10/10 loss 0.23\n",
      "epoch 54 iter10/10 loss 0.222\n",
      "epoch 55 iter10/10 loss 0.226\n",
      "epoch 56 iter10/10 loss 0.225\n",
      "epoch 57 iter10/10 loss 0.224\n",
      "epoch 58 iter10/10 loss 0.225\n",
      "epoch 59 iter10/10 loss 0.224\n",
      "epoch 60 iter10/10 loss 0.209\n",
      "epoch 61 iter10/10 loss 0.216\n",
      "epoch 62 iter10/10 loss 0.21\n",
      "epoch 63 iter10/10 loss 0.225\n",
      "epoch 64 iter10/10 loss 0.205\n",
      "epoch 65 iter10/10 loss 0.195\n",
      "epoch 66 iter10/10 loss 0.199\n",
      "epoch 67 iter10/10 loss 0.183\n",
      "epoch 68 iter10/10 loss 0.207\n",
      "epoch 69 iter10/10 loss 0.193\n",
      "epoch 70 iter10/10 loss 0.175\n",
      "epoch 71 iter10/10 loss 0.176\n",
      "epoch 72 iter10/10 loss 0.187\n",
      "epoch 73 iter10/10 loss 0.171\n",
      "epoch 74 iter10/10 loss 0.172\n",
      "epoch 75 iter10/10 loss 0.166\n",
      "epoch 76 iter10/10 loss 0.176\n",
      "epoch 77 iter10/10 loss 0.188\n",
      "epoch 78 iter10/10 loss 0.16\n",
      "epoch 79 iter10/10 loss 0.164\n",
      "epoch 80 iter10/10 loss 0.161\n",
      "epoch 81 iter10/10 loss 0.176\n",
      "epoch 82 iter10/10 loss 0.158\n",
      "epoch 83 iter10/10 loss 0.18\n",
      "epoch 84 iter10/10 loss 0.161\n",
      "epoch 85 iter10/10 loss 0.159\n",
      "epoch 86 iter10/10 loss 0.154\n",
      "epoch 87 iter10/10 loss 0.161\n",
      "epoch 88 iter10/10 loss 0.159\n",
      "epoch 89 iter10/10 loss 0.162\n",
      "epoch 90 iter10/10 loss 0.153\n",
      "epoch 91 iter10/10 loss 0.154\n",
      "epoch 92 iter10/10 loss 0.166\n",
      "epoch 93 iter10/10 loss 0.153\n",
      "epoch 94 iter10/10 loss 0.142\n",
      "epoch 95 iter10/10 loss 0.16\n",
      "epoch 96 iter10/10 loss 0.156\n",
      "epoch 97 iter10/10 loss 0.139\n",
      "epoch 98 iter10/10 loss 0.15\n",
      "epoch 99 iter10/10 loss 0.14\n",
      "epoch 100 iter10/10 loss 0.139\n",
      "epoch 101 iter10/10 loss 0.143\n",
      "epoch 102 iter10/10 loss 0.135\n",
      "epoch 103 iter10/10 loss 0.136\n",
      "epoch 104 iter10/10 loss 0.19\n",
      "epoch 105 iter10/10 loss 0.166\n",
      "epoch 106 iter10/10 loss 0.137\n",
      "epoch 107 iter10/10 loss 0.164\n",
      "epoch 108 iter10/10 loss 0.147\n",
      "epoch 109 iter10/10 loss 0.138\n",
      "epoch 110 iter10/10 loss 0.139\n",
      "epoch 111 iter10/10 loss 0.128\n",
      "epoch 112 iter10/10 loss 0.129\n",
      "epoch 113 iter10/10 loss 0.129\n",
      "epoch 114 iter10/10 loss 0.136\n",
      "epoch 115 iter10/10 loss 0.124\n",
      "epoch 116 iter10/10 loss 0.128\n",
      "epoch 117 iter10/10 loss 0.135\n",
      "epoch 118 iter10/10 loss 0.116\n",
      "epoch 119 iter10/10 loss 0.13\n",
      "epoch 120 iter10/10 loss 0.125\n",
      "epoch 121 iter10/10 loss 0.131\n",
      "epoch 122 iter10/10 loss 0.125\n",
      "epoch 123 iter10/10 loss 0.14\n",
      "epoch 124 iter10/10 loss 0.129\n",
      "epoch 125 iter10/10 loss 0.127\n",
      "epoch 126 iter10/10 loss 0.129\n",
      "epoch 127 iter10/10 loss 0.116\n",
      "epoch 128 iter10/10 loss 0.111\n",
      "epoch 129 iter10/10 loss 0.128\n",
      "epoch 130 iter10/10 loss 0.128\n",
      "epoch 131 iter10/10 loss 0.13\n",
      "epoch 132 iter10/10 loss 0.119\n",
      "epoch 133 iter10/10 loss 0.129\n",
      "epoch 134 iter10/10 loss 0.125\n",
      "epoch 135 iter10/10 loss 0.111\n",
      "epoch 136 iter10/10 loss 0.112\n",
      "epoch 137 iter10/10 loss 0.127\n",
      "epoch 138 iter10/10 loss 0.11\n",
      "epoch 139 iter10/10 loss 0.11\n",
      "epoch 140 iter10/10 loss 0.109\n",
      "epoch 141 iter10/10 loss 0.107\n",
      "epoch 142 iter10/10 loss 0.124\n",
      "epoch 143 iter10/10 loss 0.119\n",
      "epoch 144 iter10/10 loss 0.117\n",
      "epoch 145 iter10/10 loss 0.097\n",
      "epoch 146 iter10/10 loss 0.112\n",
      "epoch 147 iter10/10 loss 0.103\n",
      "epoch 148 iter10/10 loss 0.12\n",
      "epoch 149 iter10/10 loss 0.12\n",
      "epoch 150 iter10/10 loss 0.124\n",
      "epoch 151 iter10/10 loss 0.127\n",
      "epoch 152 iter10/10 loss 0.111\n",
      "epoch 153 iter10/10 loss 0.107\n",
      "epoch 154 iter10/10 loss 0.108\n",
      "epoch 155 iter10/10 loss 0.101\n",
      "epoch 156 iter10/10 loss 0.117\n",
      "epoch 157 iter10/10 loss 0.112\n",
      "epoch 158 iter10/10 loss 0.099\n",
      "epoch 159 iter10/10 loss 0.107\n",
      "epoch 160 iter10/10 loss 0.102\n",
      "epoch 161 iter10/10 loss 0.095\n",
      "epoch 162 iter10/10 loss 0.1\n",
      "epoch 163 iter10/10 loss 0.108\n",
      "epoch 164 iter10/10 loss 0.1\n",
      "epoch 165 iter10/10 loss 0.118\n",
      "epoch 166 iter10/10 loss 0.098\n",
      "epoch 167 iter10/10 loss 0.1\n",
      "epoch 168 iter10/10 loss 0.114\n",
      "epoch 169 iter10/10 loss 0.097\n",
      "epoch 170 iter10/10 loss 0.142\n",
      "epoch 171 iter10/10 loss 0.11\n",
      "epoch 172 iter10/10 loss 0.117\n",
      "epoch 173 iter10/10 loss 0.094\n",
      "epoch 174 iter10/10 loss 0.123\n",
      "epoch 175 iter10/10 loss 0.094\n",
      "epoch 176 iter10/10 loss 0.109\n",
      "epoch 177 iter10/10 loss 0.112\n",
      "epoch 178 iter10/10 loss 0.116\n",
      "epoch 179 iter10/10 loss 0.097\n",
      "epoch 180 iter10/10 loss 0.102\n",
      "epoch 181 iter10/10 loss 0.108\n",
      "epoch 182 iter10/10 loss 0.107\n",
      "epoch 183 iter10/10 loss 0.102\n",
      "epoch 184 iter10/10 loss 0.096\n",
      "epoch 185 iter10/10 loss 0.094\n",
      "epoch 186 iter10/10 loss 0.095\n",
      "epoch 187 iter10/10 loss 0.099\n",
      "epoch 188 iter10/10 loss 0.096\n",
      "epoch 189 iter10/10 loss 0.1\n",
      "epoch 190 iter10/10 loss 0.094\n",
      "epoch 191 iter10/10 loss 0.096\n",
      "epoch 192 iter10/10 loss 0.091\n",
      "epoch 193 iter10/10 loss 0.103\n",
      "epoch 194 iter10/10 loss 0.083\n",
      "epoch 195 iter10/10 loss 0.098\n",
      "epoch 196 iter10/10 loss 0.087\n",
      "epoch 197 iter10/10 loss 0.093\n",
      "epoch 198 iter10/10 loss 0.098\n",
      "epoch 199 iter10/10 loss 0.1\n",
      "epoch 200 iter10/10 loss 0.099\n",
      "epoch 201 iter10/10 loss 0.08\n",
      "epoch 202 iter10/10 loss 0.127\n",
      "epoch 203 iter10/10 loss 0.09\n",
      "epoch 204 iter10/10 loss 0.101\n",
      "epoch 205 iter10/10 loss 0.077\n",
      "epoch 206 iter10/10 loss 0.079\n",
      "epoch 207 iter10/10 loss 0.09\n",
      "epoch 208 iter10/10 loss 0.124\n",
      "epoch 209 iter10/10 loss 0.098\n",
      "epoch 210 iter10/10 loss 0.121\n",
      "epoch 211 iter10/10 loss 0.094\n",
      "epoch 212 iter10/10 loss 0.092\n",
      "epoch 213 iter10/10 loss 0.094\n",
      "epoch 214 iter10/10 loss 0.103\n",
      "epoch 215 iter10/10 loss 0.082\n",
      "epoch 216 iter10/10 loss 0.111\n",
      "epoch 217 iter10/10 loss 0.09\n",
      "epoch 218 iter10/10 loss 0.086\n",
      "epoch 219 iter10/10 loss 0.099\n",
      "epoch 220 iter10/10 loss 0.093\n",
      "epoch 221 iter10/10 loss 0.109\n",
      "epoch 222 iter10/10 loss 0.092\n",
      "epoch 223 iter10/10 loss 0.091\n",
      "epoch 224 iter10/10 loss 0.09\n",
      "epoch 225 iter10/10 loss 0.088\n",
      "epoch 226 iter10/10 loss 0.091\n",
      "epoch 227 iter10/10 loss 0.085\n",
      "epoch 228 iter10/10 loss 0.103\n",
      "epoch 229 iter10/10 loss 0.082\n",
      "epoch 230 iter10/10 loss 0.095\n",
      "epoch 231 iter10/10 loss 0.08\n",
      "epoch 232 iter10/10 loss 0.094\n",
      "epoch 233 iter10/10 loss 0.093\n",
      "epoch 234 iter10/10 loss 0.083\n",
      "epoch 235 iter10/10 loss 0.087\n",
      "epoch 236 iter10/10 loss 0.09\n",
      "epoch 237 iter10/10 loss 0.091\n",
      "epoch 238 iter10/10 loss 0.086\n",
      "epoch 239 iter10/10 loss 0.087\n",
      "epoch 240 iter10/10 loss 0.088\n",
      "epoch 241 iter10/10 loss 0.082\n",
      "epoch 242 iter10/10 loss 0.091\n",
      "epoch 243 iter10/10 loss 0.089\n",
      "epoch 244 iter10/10 loss 0.129\n",
      "epoch 245 iter10/10 loss 0.127\n",
      "epoch 246 iter10/10 loss 0.103\n",
      "epoch 247 iter10/10 loss 0.083\n",
      "epoch 248 iter10/10 loss 0.072\n",
      "epoch 249 iter10/10 loss 0.094\n",
      "epoch 250 iter10/10 loss 0.085\n",
      "epoch 251 iter10/10 loss 0.096\n",
      "epoch 252 iter10/10 loss 0.089\n",
      "epoch 253 iter10/10 loss 0.072\n",
      "epoch 254 iter10/10 loss 0.088\n",
      "epoch 255 iter10/10 loss 0.089\n",
      "epoch 256 iter10/10 loss 0.081\n",
      "epoch 257 iter10/10 loss 0.084\n",
      "epoch 258 iter10/10 loss 0.086\n",
      "epoch 259 iter10/10 loss 0.121\n",
      "epoch 260 iter10/10 loss 0.083\n",
      "epoch 261 iter10/10 loss 0.091\n",
      "epoch 262 iter10/10 loss 0.073\n",
      "epoch 263 iter10/10 loss 0.08\n",
      "epoch 264 iter10/10 loss 0.095\n",
      "epoch 265 iter10/10 loss 0.079\n",
      "epoch 266 iter10/10 loss 0.09\n",
      "epoch 267 iter10/10 loss 0.084\n",
      "epoch 268 iter10/10 loss 0.092\n",
      "epoch 269 iter10/10 loss 0.077\n",
      "epoch 270 iter10/10 loss 0.082\n",
      "epoch 271 iter10/10 loss 0.077\n",
      "epoch 272 iter10/10 loss 0.085\n",
      "epoch 273 iter10/10 loss 0.081\n",
      "epoch 274 iter10/10 loss 0.078\n",
      "epoch 275 iter10/10 loss 0.091\n",
      "epoch 276 iter10/10 loss 0.075\n",
      "epoch 277 iter10/10 loss 0.104\n",
      "epoch 278 iter10/10 loss 0.084\n",
      "epoch 279 iter10/10 loss 0.09\n",
      "epoch 280 iter10/10 loss 0.075\n",
      "epoch 281 iter10/10 loss 0.087\n",
      "epoch 282 iter10/10 loss 0.08\n",
      "epoch 283 iter10/10 loss 0.078\n",
      "epoch 284 iter10/10 loss 0.077\n",
      "epoch 285 iter10/10 loss 0.092\n",
      "epoch 286 iter10/10 loss 0.078\n",
      "epoch 287 iter10/10 loss 0.073\n",
      "epoch 288 iter10/10 loss 0.126\n",
      "epoch 289 iter10/10 loss 0.078\n",
      "epoch 290 iter10/10 loss 0.109\n",
      "epoch 291 iter10/10 loss 0.083\n",
      "epoch 292 iter10/10 loss 0.085\n",
      "epoch 293 iter10/10 loss 0.087\n",
      "epoch 294 iter10/10 loss 0.076\n",
      "epoch 295 iter10/10 loss 0.076\n",
      "epoch 296 iter10/10 loss 0.075\n",
      "epoch 297 iter10/10 loss 0.07\n",
      "epoch 298 iter10/10 loss 0.095\n",
      "epoch 299 iter10/10 loss 0.058\n",
      "epoch 300 iter10/10 loss 0.106\n",
      "epoch 301 iter10/10 loss 0.072\n",
      "epoch 302 iter10/10 loss 0.073\n",
      "epoch 303 iter10/10 loss 0.08\n",
      "epoch 304 iter10/10 loss 0.071\n",
      "epoch 305 iter10/10 loss 0.073\n",
      "epoch 306 iter10/10 loss 0.091\n",
      "epoch 307 iter10/10 loss 0.083\n",
      "epoch 308 iter10/10 loss 0.073\n",
      "epoch 309 iter10/10 loss 0.079\n",
      "epoch 310 iter10/10 loss 0.094\n",
      "epoch 311 iter10/10 loss 0.072\n",
      "epoch 312 iter10/10 loss 0.073\n",
      "epoch 313 iter10/10 loss 0.085\n",
      "epoch 314 iter10/10 loss 0.076\n",
      "epoch 315 iter10/10 loss 0.078\n",
      "epoch 316 iter10/10 loss 0.089\n",
      "epoch 317 iter10/10 loss 0.085\n",
      "epoch 318 iter10/10 loss 0.082\n",
      "epoch 319 iter10/10 loss 0.082\n",
      "epoch 320 iter10/10 loss 0.077\n",
      "epoch 321 iter10/10 loss 0.079\n",
      "epoch 322 iter10/10 loss 0.088\n",
      "epoch 323 iter10/10 loss 0.082\n",
      "epoch 324 iter10/10 loss 0.08\n",
      "epoch 325 iter10/10 loss 0.073\n",
      "epoch 326 iter10/10 loss 0.082\n",
      "epoch 327 iter10/10 loss 0.08\n",
      "epoch 328 iter10/10 loss 0.07\n",
      "epoch 329 iter10/10 loss 0.081\n",
      "epoch 330 iter10/10 loss 0.082\n",
      "epoch 331 iter10/10 loss 0.098\n",
      "epoch 332 iter10/10 loss 0.088\n",
      "epoch 333 iter10/10 loss 0.077\n",
      "epoch 334 iter10/10 loss 0.076\n",
      "epoch 335 iter10/10 loss 0.078\n",
      "epoch 336 iter10/10 loss 0.081\n",
      "epoch 337 iter10/10 loss 0.074\n",
      "epoch 338 iter10/10 loss 0.074\n",
      "epoch 339 iter10/10 loss 0.068\n",
      "epoch 340 iter10/10 loss 0.068\n",
      "epoch 341 iter10/10 loss 0.075\n",
      "epoch 342 iter10/10 loss 0.074\n",
      "epoch 343 iter10/10 loss 0.078\n",
      "epoch 344 iter10/10 loss 0.078\n",
      "epoch 345 iter10/10 loss 0.073\n",
      "epoch 346 iter10/10 loss 0.072\n",
      "epoch 347 iter10/10 loss 0.074\n",
      "epoch 348 iter10/10 loss 0.072\n",
      "epoch 349 iter10/10 loss 0.071\n",
      "epoch 350 iter10/10 loss 0.127\n",
      "epoch 351 iter10/10 loss 0.072\n",
      "epoch 352 iter10/10 loss 0.079\n",
      "epoch 353 iter10/10 loss 0.129\n",
      "epoch 354 iter10/10 loss 0.078\n",
      "epoch 355 iter10/10 loss 0.074\n",
      "epoch 356 iter10/10 loss 0.073\n",
      "epoch 357 iter10/10 loss 0.089\n",
      "epoch 358 iter10/10 loss 0.08\n",
      "epoch 359 iter10/10 loss 0.073\n",
      "epoch 360 iter10/10 loss 0.071\n",
      "epoch 361 iter10/10 loss 0.079\n",
      "epoch 362 iter10/10 loss 0.072\n",
      "epoch 363 iter10/10 loss 0.084\n",
      "epoch 364 iter10/10 loss 0.082\n",
      "epoch 365 iter10/10 loss 0.087\n",
      "epoch 366 iter10/10 loss 0.071\n",
      "epoch 367 iter10/10 loss 0.079\n",
      "epoch 368 iter10/10 loss 0.07\n",
      "epoch 369 iter10/10 loss 0.071\n",
      "epoch 370 iter10/10 loss 0.07\n",
      "epoch 371 iter10/10 loss 0.088\n",
      "epoch 372 iter10/10 loss 0.074\n",
      "epoch 373 iter10/10 loss 0.074\n",
      "epoch 374 iter10/10 loss 0.078\n",
      "epoch 375 iter10/10 loss 0.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 376 iter10/10 loss 0.07\n",
      "epoch 377 iter10/10 loss 0.093\n",
      "epoch 378 iter10/10 loss 0.062\n",
      "epoch 379 iter10/10 loss 0.072\n",
      "epoch 380 iter10/10 loss 0.081\n",
      "epoch 381 iter10/10 loss 0.076\n",
      "epoch 382 iter10/10 loss 0.105\n",
      "epoch 383 iter10/10 loss 0.081\n",
      "epoch 384 iter10/10 loss 0.068\n",
      "epoch 385 iter10/10 loss 0.098\n",
      "epoch 386 iter10/10 loss 0.075\n",
      "epoch 387 iter10/10 loss 0.065\n",
      "epoch 388 iter10/10 loss 0.083\n",
      "epoch 389 iter10/10 loss 0.082\n",
      "epoch 390 iter10/10 loss 0.071\n",
      "epoch 391 iter10/10 loss 0.073\n",
      "epoch 392 iter10/10 loss 0.074\n",
      "epoch 393 iter10/10 loss 0.082\n",
      "epoch 394 iter10/10 loss 0.073\n",
      "epoch 395 iter10/10 loss 0.078\n",
      "epoch 396 iter10/10 loss 0.064\n",
      "epoch 397 iter10/10 loss 0.085\n",
      "epoch 398 iter10/10 loss 0.07\n",
      "epoch 399 iter10/10 loss 0.091\n",
      "epoch 400 iter10/10 loss 0.072\n",
      "epoch 401 iter10/10 loss 0.073\n",
      "epoch 402 iter10/10 loss 0.078\n",
      "epoch 403 iter10/10 loss 0.076\n",
      "epoch 404 iter10/10 loss 0.092\n",
      "epoch 405 iter10/10 loss 0.069\n",
      "epoch 406 iter10/10 loss 0.072\n",
      "epoch 407 iter10/10 loss 0.069\n",
      "epoch 408 iter10/10 loss 0.077\n",
      "epoch 409 iter10/10 loss 0.082\n",
      "epoch 410 iter10/10 loss 0.066\n",
      "epoch 411 iter10/10 loss 0.067\n",
      "epoch 412 iter10/10 loss 0.07\n",
      "epoch 413 iter10/10 loss 0.119\n",
      "epoch 414 iter10/10 loss 0.064\n",
      "epoch 415 iter10/10 loss 0.071\n",
      "epoch 416 iter10/10 loss 0.066\n",
      "epoch 417 iter10/10 loss 0.073\n",
      "epoch 418 iter10/10 loss 0.07\n",
      "epoch 419 iter10/10 loss 0.084\n",
      "epoch 420 iter10/10 loss 0.081\n",
      "epoch 421 iter10/10 loss 0.069\n",
      "epoch 422 iter10/10 loss 0.06\n",
      "epoch 423 iter10/10 loss 0.087\n",
      "epoch 424 iter10/10 loss 0.067\n",
      "epoch 425 iter10/10 loss 0.074\n",
      "epoch 426 iter10/10 loss 0.086\n",
      "epoch 427 iter10/10 loss 0.065\n",
      "epoch 428 iter10/10 loss 0.067\n",
      "epoch 429 iter10/10 loss 0.069\n",
      "epoch 430 iter10/10 loss 0.085\n",
      "epoch 431 iter10/10 loss 0.071\n",
      "epoch 432 iter10/10 loss 0.067\n",
      "epoch 433 iter10/10 loss 0.068\n",
      "epoch 434 iter10/10 loss 0.085\n",
      "epoch 435 iter10/10 loss 0.101\n",
      "epoch 436 iter10/10 loss 0.07\n",
      "epoch 437 iter10/10 loss 0.07\n",
      "epoch 438 iter10/10 loss 0.068\n",
      "epoch 439 iter10/10 loss 0.078\n",
      "epoch 440 iter10/10 loss 0.072\n",
      "epoch 441 iter10/10 loss 0.083\n",
      "epoch 442 iter10/10 loss 0.067\n",
      "epoch 443 iter10/10 loss 0.065\n",
      "epoch 444 iter10/10 loss 0.06\n",
      "epoch 445 iter10/10 loss 0.073\n",
      "epoch 446 iter10/10 loss 0.069\n",
      "epoch 447 iter10/10 loss 0.076\n",
      "epoch 448 iter10/10 loss 0.064\n",
      "epoch 449 iter10/10 loss 0.061\n",
      "epoch 450 iter10/10 loss 0.072\n",
      "epoch 451 iter10/10 loss 0.076\n",
      "epoch 452 iter10/10 loss 0.073\n",
      "epoch 453 iter10/10 loss 0.066\n",
      "epoch 454 iter10/10 loss 0.065\n",
      "epoch 455 iter10/10 loss 0.067\n",
      "epoch 456 iter10/10 loss 0.086\n",
      "epoch 457 iter10/10 loss 0.071\n",
      "epoch 458 iter10/10 loss 0.094\n",
      "epoch 459 iter10/10 loss 0.071\n",
      "epoch 460 iter10/10 loss 0.083\n",
      "epoch 461 iter10/10 loss 0.063\n",
      "epoch 462 iter10/10 loss 0.077\n",
      "epoch 463 iter10/10 loss 0.077\n",
      "epoch 464 iter10/10 loss 0.114\n",
      "epoch 465 iter10/10 loss 0.061\n",
      "epoch 466 iter10/10 loss 0.07\n",
      "epoch 467 iter10/10 loss 0.068\n",
      "epoch 468 iter10/10 loss 0.071\n",
      "epoch 469 iter10/10 loss 0.073\n",
      "epoch 470 iter10/10 loss 0.069\n",
      "epoch 471 iter10/10 loss 0.078\n",
      "epoch 472 iter10/10 loss 0.066\n",
      "epoch 473 iter10/10 loss 0.067\n",
      "epoch 474 iter10/10 loss 0.063\n",
      "epoch 475 iter10/10 loss 0.07\n",
      "epoch 476 iter10/10 loss 0.067\n",
      "epoch 477 iter10/10 loss 0.076\n",
      "epoch 478 iter10/10 loss 0.064\n",
      "epoch 479 iter10/10 loss 0.074\n",
      "epoch 480 iter10/10 loss 0.065\n",
      "epoch 481 iter10/10 loss 0.063\n",
      "epoch 482 iter10/10 loss 0.067\n",
      "epoch 483 iter10/10 loss 0.075\n",
      "epoch 484 iter10/10 loss 0.057\n",
      "epoch 485 iter10/10 loss 0.081\n",
      "epoch 486 iter10/10 loss 0.075\n",
      "epoch 487 iter10/10 loss 0.065\n",
      "epoch 488 iter10/10 loss 0.07\n",
      "epoch 489 iter10/10 loss 0.073\n",
      "epoch 490 iter10/10 loss 0.073\n",
      "epoch 491 iter10/10 loss 0.064\n",
      "epoch 492 iter10/10 loss 0.074\n",
      "epoch 493 iter10/10 loss 0.079\n",
      "epoch 494 iter10/10 loss 0.083\n",
      "epoch 495 iter10/10 loss 0.065\n",
      "epoch 496 iter10/10 loss 0.067\n",
      "epoch 497 iter10/10 loss 0.076\n",
      "epoch 498 iter10/10 loss 0.062\n",
      "epoch 499 iter10/10 loss 0.086\n",
      "epoch 500 iter10/10 loss 0.07\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_count, total_loss = 0, 0\n",
    " \n",
    "for epoch in range(epochs):\n",
    "    # 0 ～ N までのランダムの値をN個用意する\n",
    "    index = np.random.permutation(N)\n",
    "    # シャッフル動作\n",
    "    x = x[index]\n",
    "    t = t[index]\n",
    "    \n",
    "    for iters in range(max_iters):\n",
    "        # xからbatch_sizeごとに順番に取り出す\n",
    "        batch_x = x[iters*batch_size : (iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size : (iters+1)*batch_size]\n",
    "        \n",
    "        # 順伝播\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        # 勾配を求める\n",
    "        model.backward()\n",
    "        # 現在のパラメータの値と勾配情報を渡し、SGDを行う\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        # 定期的に学習経過を出力\n",
    "        if(iters+1)%10 == 0:\n",
    "            ave_loss = total_loss/loss_count\n",
    "            print('epoch {} iter{}/{} loss {}'.format(epoch+1, iters+1, max_iters, round(ave_loss, 3)))\n",
    "            losses.append(ave_loss)\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.4, 2.9, 4.3, 1.3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(x[0])\n",
    "y = np.argmax(softmax(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0,\n",
       "       0, 0, 1, 0, 2, 0, 1, 0, 2, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 0, 0, 1,\n",
       "       0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0,\n",
       "       1, 1, 0, 2, 0, 2, 1, 1, 2, 1, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 1, 2,\n",
       "       2, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 0, 1, 2, 0, 0, 2,\n",
       "       2, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 1, 1, 2, 1, 0,\n",
       "       0, 0, 2, 0, 0, 1, 0, 1, 2, 2, 1, 0, 0, 2, 1, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(x)\n",
    "y = np.argmax(softmax(y), axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
